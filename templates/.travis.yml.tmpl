language: bash

env:
  global:
  - DOCKER_IMAGE="spark-jupyterhub"
  - FROM_DOCKER_IMAGE="guangie88/spark-k8s-addons"

matrix:
  include:
{%- for v in versions %}
{%- for jupyterhub in v.jupyterhub %}
{%- for spark in v.spark %}
{%- for hadoop in v.hadoop %}
  - services: docker
    env:
    - JUPYTERHUB_VERSION={{ jupyterhub }}
    - SPARK_VERSION={{ spark }}
    - HADOOP_VERSION={{ hadoop }}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}

script:
- FROM_DOCKER_TAG="${SPARK_VERSION}_hadoop-${HADOOP_VERSION}"
- PY4J_SRC="$(docker run --rm -t --entrypoint bash ${FROM_DOCKER_IMAGE}:${FROM_DOCKER_TAG} -c 'ls ${SPARK_HOME}/python/lib/py4j* | sed -E "s/.+(py4j-.+)/\1/" | tr -d "\n"')"
- echo "PY4J_SRC=${PY4J_SRC}"
- |-
  docker build . \
    --build-arg "FROM_DOCKER_IMAGE=${FROM_DOCKER_IMAGE}" \
    --build-arg "JUPYTERHUB_VERSION=${JUPYTERHUB_VERSION}" \
    --build-arg "SPARK_VERSION=${SPARK_VERSION}" \
    --build-arg "HADOOP_VERSION=${HADOOP_VERSION}" \
    --build-arg "PY4J_SRC=${PY4J_SRC}" \
    -t "${DOCKER_IMAGE}:${JUPYTERHUB_VERSION}_spark-${SPARK_VERSION}_hadoop-${HADOOP_VERSION}"

deploy:
  provider: script
  script: bash push-images.sh
  on:
    branch: master

branches:
  only:
  - master
