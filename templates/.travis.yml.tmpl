language: bash

env:
  global:
  - DOCKER_IMAGE="guangie88/spark-jupyterhub"
  - FROM_DOCKER_IMAGE="guangie88/spark-custom-addons"

matrix:
  include:
{%- for v in versions %}
  - services: docker
    env:
    - SPARK_VERSION={{ v.spark }}
    - HADOOP_VERSION={{ v.hadoop }}
    - AWS_JAVA_SDK_VERSION={{ v.aws_java_sdk }}
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
{%- endfor %}

script:
- FROM_DOCKER_TAG=${SPARK_VERSION}_hadoop-${HADOOP_VERSION}${HIVE_TAG_SUFFIX}${PYSPARK_TAG_SUFFIX}_debian
- PY4J_SRC=$(docker run --rm -t ${FROM_DOCKER_IMAGE}:${FROM_DOCKER_TAG} sh -c 'ls ${SPARK_HOME}/python/lib/py4j* | sed -E "s/.+(py4j-.+)/\1/" | tr -d "\n"')
- |-
  docker build . \
    --build-arg FROM_DOCKER_IMAGE \
    --build-arg SPARK_VERSION=${SPARK_VERSION} \
    --build-arg HADOOP_VERSION=${HADOOP_VERSION} \
    --build-arg PY4J_SRC=${PY4J_SRC} \
    -t "${DOCKER_IMAGE}:${SPARK_VERSION}_hadoop-${HADOOP_VERSION}"

deploy:
  provider: script
  script: bash push-images.sh
  on:
    branch: master

branches:
  only:
  - master
