language: bash

env:
  global:
  - DOCKER_IMAGE="guangie88/spark-jupyterhub"
  - FROM_DOCKER_IMAGE="guangie88/spark-custom-addons"

matrix:
  include:
  - services: docker
    env:
    - SPARK_VERSION=2.3.0
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.3.1
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.3.2
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.3.3
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.0
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.0
    - HADOOP_VERSION=3.1.0
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.1
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.1
    - HADOOP_VERSION=3.1.0
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.2
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.2
    - HADOOP_VERSION=3.1.0
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.3
    - HADOOP_VERSION=2.7.3
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark
  - services: docker
    env:
    - SPARK_VERSION=2.4.3
    - HADOOP_VERSION=3.1.0
    - HIVE_TAG_SUFFIX=_hive
    - PYSPARK_TAG_SUFFIX=_pyspark

script:
- FROM_DOCKER_TAG=${SPARK_VERSION}_hadoop-${HADOOP_VERSION}${HIVE_TAG_SUFFIX}${PYSPARK_TAG_SUFFIX}_debian
- PY4J_SRC=$(docker run --rm -t ${FROM_DOCKER_IMAGE}:${FROM_DOCKER_TAG} sh -c 'ls ${SPARK_HOME}/python/lib/py4j* | sed -E "s/.+(py4j-.+)/\1/" | tr -d "\n"')
- |-
  docker build . \
    --build-arg FROM_DOCKER_IMAGE=${FROM_DOCKER_IMAGE} \
    --build-arg SPARK_VERSION=${SPARK_VERSION} \
    --build-arg HADOOP_VERSION=${HADOOP_VERSION} \
    --build-arg HIVE_TAG_SUFFIX=${HIVE_TAG_SUFFIX} \
    --build-arg PYSPARK_TAG_SUFFIX=${PYSPARK_TAG_SUFFIX} \
    --build-arg PY4J_SRC=${PY4J_SRC} \
    -t "${DOCKER_IMAGE}:${SPARK_VERSION}_hadoop-${HADOOP_VERSION}"

deploy:
  provider: script
  script: bash push-images.sh
  on:
    branch: master

branches:
  only:
  - master
